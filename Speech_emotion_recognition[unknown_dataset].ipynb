{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSE-221710315024-LIKHITA YANAMADDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNKNOWN DATASET DRIVE LINK: \n",
    "https://drive.google.com/drive/folders/1eTvCwBkJBmChWjsPfvbg8kfkSqTo-iyL?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "kvMPFneF2Um_",
    "outputId": "7e36e196-8024-46ab-f5d2-8a6d55895f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HPv223Td2cDa",
    "outputId": "c2a41c4c-3930-42b2-ca68-c9ffc1ac3298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FJ2exgu2m9E"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "# librosa is a Python library for analyzing audio and music.\n",
    "# It has a flatter package layout, standardizes interfaces and names,\n",
    "# backwards compatibility, modular functions, and readable code.\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#define a dictionary to hold numbers and the emotions available in the \n",
    "#RAVDESS dataset, and a list to hold those we want- angry,sad, neutral, happy.\n",
    "\n",
    "\n",
    "#this is the Ryerson Audio-Visual Database of Emotional Speech and Song dataset,\n",
    "#This dataset has 7356 files rated by 247 individuals 10 times on emotional \n",
    "# validity, intensity, and genuineness. The entire dataset is 24.8GB from\n",
    "# 24 actors, but weâ€™ve lowered the sample rate on all the files.\n",
    "\n",
    "# all emotions on RAVDESS dataset\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# we allow only these emotions\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"neutral\",\n",
    "    \"happy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2C1nUjCQ2ygq"
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5QcR2-T22Be"
   },
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    X, y = [], []\n",
    "    try :\n",
    "      for file in glob.glob(\"/content/drive/My Drive/Colab Notebooks/data set/AudioData\"):\n",
    "          # get the base name of the audio file\n",
    "          basename = os.path.basename(file)\n",
    "          print(basename)\n",
    "          # get the emotion label\n",
    "          emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "          # we allow only AVAILABLE_EMOTIONS we set\n",
    "          if emotion not in AVAILABLE_EMOTIONS:\n",
    "              continue\n",
    "          # extract speech features\n",
    "          features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "          # add to data\n",
    "          X.append(features)\n",
    "          l={'happy':0.0,'sad':1.0,'neutral':3.0,'angry':4.0}\n",
    "          y.append(l[emotion])\n",
    "    except :\n",
    "         pass\n",
    "    # split the data to training and testing and return it\n",
    "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJLVzLj9xJ6k"
   },
   "outputs": [],
   "source": [
    "sample_file = '/content/drive/My Drive/Colab Notebooks/data set/AudioData/DC/a01.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCoPuX-lxKJH"
   },
   "outputs": [],
   "source": [
    "# Load the audio data with librosa from .wav file\n",
    "# input path \n",
    "data, sampling_rate = librosa.load(sample_file)\n",
    "# output is data teh discrete values, sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AXGEyKycxac4",
    "outputId": "9d2f7e92-2808-449d-b215-64a86f29e3c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80434,)"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Audio sampled data ouput shape\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ADgQsIWmxapf",
    "outputId": "bc7e9ddc-8fd6-42db-d259-97d2cf4fd68c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aS1StBG3xuyX",
    "outputId": "3cd13a29-2215-4916-85a3-d1dd7f6f8b11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110250,)"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, sample_rate = librosa.load(sample_file, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7tvGI5bJx7su",
    "outputId": "cab064c4-587c-41dd-f18b-47913d0c3648"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441000"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10*22050*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "IJirLhnNx7zg",
    "outputId": "194b60a1-dcac-4eca-afd6-7d966021cc43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08215332, 0.0809021 , 0.07754517, ..., 0.21911621, 0.19934082,\n",
       "       0.17391968], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "wfAmPOavx78P",
    "outputId": "c86d18e4-b12f-42d8-d9a3-d6631b7583de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-318.34907634, -289.72019185, -269.75849637, ..., -219.42767604,\n",
       "        -209.46609287, -180.1187328 ],\n",
       "       [  83.44985313,  135.30527971,  182.35460902, ...,  229.88559252,\n",
       "         238.01667462,  248.71813002],\n",
       "       [ -54.12408135,   -7.18993656,   16.98681678, ...,   -4.90131715,\n",
       "          -0.33663499,   -1.15097019],\n",
       "       ...,\n",
       "       [ -11.183432  ,  -10.80955344,   -9.52499654, ...,  -32.88296871,\n",
       "         -32.24869379,  -24.09375983],\n",
       "       [ -10.36455051,  -15.87282497,  -20.11362012, ...,  -16.86774535,\n",
       "         -12.20967621,  -13.46425284],\n",
       "       [  -0.92029628,   -8.4874924 ,  -13.82025247, ...,    4.01767426,\n",
       "           8.50465788,   10.81932434]])"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m2mGcACyx8AP",
    "outputId": "e29f983e-8e95-44eb-e3ec-9ab059551855"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 216)"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GspM82isx760",
    "outputId": "83743fe6-0862-48e4-89be-38213c7f2868"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216,)"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4VgYknvN6Iyd",
    "outputId": "76eb0a44-ba15-40c8-b996-d3f95cd92ff5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JK', 'KL', 'JE', 'DC']"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '/content/drive/My Drive/Colab Notebooks/data set/AudioData'\n",
    "folders = [fol  for fol in os.listdir(base_path) if os.path.isdir(base_path+'/'+fol)]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "RsIpDsla6Z9V",
    "outputId": "a6809c3a-e95c-43c0-bf33-8bf5307fcd81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 JK\n",
      "1 KL\n",
      "2 JE\n",
      "3 DC\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['feature']) # empty dataframe with a single column feature\n",
    "bookmark=0 # Row count\n",
    "for cls,per in enumerate(folders): # Folder name with label\n",
    "  # labels are from 0 to 3\n",
    "  print(cls,per)\n",
    "\n",
    "  for name in os.listdir(base_path+'/'+per):\n",
    "        X, sample_rate = librosa.load(base_path+'/'+per+'/'+name, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        # shape of x is sr*duration\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        # 216 values\n",
    "        feature = mfccs\n",
    "        # Appending class label to numpy array\n",
    "        feature = np.append(feature,cls)\n",
    "        # In each row we have a single column\n",
    "        # In that column I have a numpy array as value\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "xWyO7b1w6do8",
    "outputId": "e38c6d9c-e430-4087-bf0e-77e3f58fc976"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-14.260570089536198, -9.794443423477855, -7.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-23.24786881445334, -21.8824322667551, -22.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-24.4791672217428, -23.70163006309942, -23.76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-27.43689401546252, -25.614000968041886, -23....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4.857962390413935, 2.180288304326841, -2.7702...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-14.260570089536198, -9.794443423477855, -7.3...\n",
       "1  [-23.24786881445334, -21.8824322667551, -22.46...\n",
       "2  [-24.4791672217428, -23.70163006309942, -23.76...\n",
       "3  [-27.43689401546252, -25.614000968041886, -23....\n",
       "4  [4.857962390413935, 2.180288304326841, -2.7702..."
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YgoZySbV7dxP",
    "outputId": "15429c9d-b62c-4fe1-c609-4943bd49e27e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217,)"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CM6oP_S77hhY",
    "outputId": "e27f77f2-dfa4-484c-eff3-ca314253c029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature'][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZEavMJSY7jup",
    "outputId": "56d45bc0-b404-46c7-d34a-5ff903e48f98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xM3273zR7l5U",
    "outputId": "4dbe6d85-7f9c-48d6-cd66-b4980b894100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217,)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "ykAH8hrA7pJ5",
    "outputId": "2ba7dbdc-5c9e-4d2c-9924-d05654ed4dc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-23.247869</td>\n",
       "      <td>-21.882432</td>\n",
       "      <td>-22.464536</td>\n",
       "      <td>-21.925376</td>\n",
       "      <td>-21.525039</td>\n",
       "      <td>-21.747856</td>\n",
       "      <td>-22.579142</td>\n",
       "      <td>-22.473597</td>\n",
       "      <td>-13.029367</td>\n",
       "      <td>-3.608036</td>\n",
       "      <td>0.504552</td>\n",
       "      <td>-0.123957</td>\n",
       "      <td>-2.019746</td>\n",
       "      <td>-3.087927</td>\n",
       "      <td>-4.519319</td>\n",
       "      <td>-5.866865</td>\n",
       "      <td>-7.123424</td>\n",
       "      <td>-7.768707</td>\n",
       "      <td>-8.157277</td>\n",
       "      <td>-9.714922</td>\n",
       "      <td>-11.462122</td>\n",
       "      <td>-11.60833</td>\n",
       "      <td>-11.711986</td>\n",
       "      <td>-13.501631</td>\n",
       "      <td>-12.292124</td>\n",
       "      <td>-11.348449</td>\n",
       "      <td>-11.12915</td>\n",
       "      <td>-10.081434</td>\n",
       "      <td>-10.133344</td>\n",
       "      <td>-11.34308</td>\n",
       "      <td>-11.081588</td>\n",
       "      <td>-10.84629</td>\n",
       "      <td>-10.586519</td>\n",
       "      <td>-9.26417</td>\n",
       "      <td>-9.075927</td>\n",
       "      <td>-8.471176</td>\n",
       "      <td>-7.842408</td>\n",
       "      <td>-6.658286</td>\n",
       "      <td>-5.380388</td>\n",
       "      <td>-3.658577</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.488512</td>\n",
       "      <td>-12.627724</td>\n",
       "      <td>-12.913944</td>\n",
       "      <td>-15.011854</td>\n",
       "      <td>-18.860261</td>\n",
       "      <td>-21.238805</td>\n",
       "      <td>-22.137217</td>\n",
       "      <td>-23.915206</td>\n",
       "      <td>-27.00336</td>\n",
       "      <td>-24.358719</td>\n",
       "      <td>-14.958878</td>\n",
       "      <td>-10.066057</td>\n",
       "      <td>-6.843982</td>\n",
       "      <td>-4.492913</td>\n",
       "      <td>-3.191575</td>\n",
       "      <td>-2.834656</td>\n",
       "      <td>-2.298204</td>\n",
       "      <td>-3.023312</td>\n",
       "      <td>-3.524936</td>\n",
       "      <td>-3.866469</td>\n",
       "      <td>-4.236668</td>\n",
       "      <td>-6.075979</td>\n",
       "      <td>-6.462602</td>\n",
       "      <td>-6.490086</td>\n",
       "      <td>-5.523988</td>\n",
       "      <td>-6.808219</td>\n",
       "      <td>-11.169137</td>\n",
       "      <td>-17.340306</td>\n",
       "      <td>-20.582039</td>\n",
       "      <td>-22.259705</td>\n",
       "      <td>-23.84677</td>\n",
       "      <td>-23.867451</td>\n",
       "      <td>-25.314444</td>\n",
       "      <td>-24.120343</td>\n",
       "      <td>-25.423557</td>\n",
       "      <td>-25.774556</td>\n",
       "      <td>-22.357973</td>\n",
       "      <td>-22.273973</td>\n",
       "      <td>-24.853915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2    ...        214        215  216\n",
       "1 -23.247869 -21.882432 -22.464536  ... -22.273973 -24.853915  0.0\n",
       "\n",
       "[1 rows x 217 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(df['feature'].values.tolist())\n",
    "df2.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "3BV6Kr4Q7rYt",
    "outputId": "72882d4f-d159-4cad-c7a0-51558c06cd41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2      42\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "474     0\n",
       "475     0\n",
       "476     0\n",
       "477     0\n",
       "478     0\n",
       "Length: 479, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "GLkSkLgS7uCs",
    "outputId": "e1f6cc28-fe7e-4bab-f987-00d7007d62f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "      ... \n",
       "212    100\n",
       "213    101\n",
       "214    101\n",
       "215    102\n",
       "216    103\n",
       "Length: 217, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mk7wWVg57wSi"
   },
   "outputs": [],
   "source": [
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l8LNwjp87z1p",
    "outputId": "44d862db-5331-46f3-b35e-e8021c5dbea7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[216].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZeedHcf674tO",
    "outputId": "c73fe4c8-7e19-429c-f43e-518281a4dbc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[216].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l5dol6xc78qS",
    "outputId": "fcc59203-30e5-43c5-e2ef-143c30e4992a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 217)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "q8QxpN0P7_bu",
    "outputId": "56d8bfd1-1b54-408d-8a16-d73752f87970"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-14.260570</td>\n",
       "      <td>-9.794443</td>\n",
       "      <td>-7.310346</td>\n",
       "      <td>-7.640629</td>\n",
       "      <td>-8.021557</td>\n",
       "      <td>-7.615273</td>\n",
       "      <td>-7.358042</td>\n",
       "      <td>-6.709244</td>\n",
       "      <td>-6.135356</td>\n",
       "      <td>-5.676173</td>\n",
       "      <td>-5.211756</td>\n",
       "      <td>-5.024892</td>\n",
       "      <td>-4.131107</td>\n",
       "      <td>-2.656021</td>\n",
       "      <td>-3.130630</td>\n",
       "      <td>-3.866640</td>\n",
       "      <td>-5.847810</td>\n",
       "      <td>-8.843728</td>\n",
       "      <td>-8.957204</td>\n",
       "      <td>-8.453608</td>\n",
       "      <td>-8.555447</td>\n",
       "      <td>-9.160208</td>\n",
       "      <td>-8.053834</td>\n",
       "      <td>-5.311407</td>\n",
       "      <td>-4.671359</td>\n",
       "      <td>-5.452521</td>\n",
       "      <td>-5.768856</td>\n",
       "      <td>-8.011673</td>\n",
       "      <td>-6.291604</td>\n",
       "      <td>-5.106327</td>\n",
       "      <td>-6.533547</td>\n",
       "      <td>-8.885064</td>\n",
       "      <td>-10.042996</td>\n",
       "      <td>-9.022891</td>\n",
       "      <td>-8.517752</td>\n",
       "      <td>-7.578184</td>\n",
       "      <td>-6.954819</td>\n",
       "      <td>-8.240691</td>\n",
       "      <td>-9.762851</td>\n",
       "      <td>-8.814780</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.060320</td>\n",
       "      <td>-5.065291</td>\n",
       "      <td>-4.523791</td>\n",
       "      <td>-3.231164</td>\n",
       "      <td>-2.773706</td>\n",
       "      <td>-2.120986</td>\n",
       "      <td>-2.896464</td>\n",
       "      <td>-2.772844</td>\n",
       "      <td>-1.174609</td>\n",
       "      <td>-0.549480</td>\n",
       "      <td>-0.086967</td>\n",
       "      <td>-0.454265</td>\n",
       "      <td>-2.171774</td>\n",
       "      <td>-4.466500</td>\n",
       "      <td>-8.574751</td>\n",
       "      <td>-12.943460</td>\n",
       "      <td>-17.648609</td>\n",
       "      <td>-19.347770</td>\n",
       "      <td>-18.138855</td>\n",
       "      <td>-8.223878</td>\n",
       "      <td>-4.072290</td>\n",
       "      <td>-3.252632</td>\n",
       "      <td>-3.292147</td>\n",
       "      <td>-5.184165</td>\n",
       "      <td>-6.215199</td>\n",
       "      <td>-8.214097</td>\n",
       "      <td>-9.955403</td>\n",
       "      <td>-12.292212</td>\n",
       "      <td>-13.567167</td>\n",
       "      <td>-13.965576</td>\n",
       "      <td>-10.343874</td>\n",
       "      <td>-7.896760</td>\n",
       "      <td>-7.816537</td>\n",
       "      <td>-8.215529</td>\n",
       "      <td>-7.872012</td>\n",
       "      <td>-6.891598</td>\n",
       "      <td>-4.735453</td>\n",
       "      <td>-2.250857</td>\n",
       "      <td>-1.219765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-23.247869</td>\n",
       "      <td>-21.882432</td>\n",
       "      <td>-22.464536</td>\n",
       "      <td>-21.925376</td>\n",
       "      <td>-21.525039</td>\n",
       "      <td>-21.747856</td>\n",
       "      <td>-22.579142</td>\n",
       "      <td>-22.473597</td>\n",
       "      <td>-13.029367</td>\n",
       "      <td>-3.608036</td>\n",
       "      <td>0.504552</td>\n",
       "      <td>-0.123957</td>\n",
       "      <td>-2.019746</td>\n",
       "      <td>-3.087927</td>\n",
       "      <td>-4.519319</td>\n",
       "      <td>-5.866865</td>\n",
       "      <td>-7.123424</td>\n",
       "      <td>-7.768707</td>\n",
       "      <td>-8.157277</td>\n",
       "      <td>-9.714922</td>\n",
       "      <td>-11.462122</td>\n",
       "      <td>-11.608330</td>\n",
       "      <td>-11.711986</td>\n",
       "      <td>-13.501631</td>\n",
       "      <td>-12.292124</td>\n",
       "      <td>-11.348449</td>\n",
       "      <td>-11.129150</td>\n",
       "      <td>-10.081434</td>\n",
       "      <td>-10.133344</td>\n",
       "      <td>-11.343080</td>\n",
       "      <td>-11.081588</td>\n",
       "      <td>-10.846290</td>\n",
       "      <td>-10.586519</td>\n",
       "      <td>-9.264170</td>\n",
       "      <td>-9.075927</td>\n",
       "      <td>-8.471176</td>\n",
       "      <td>-7.842408</td>\n",
       "      <td>-6.658286</td>\n",
       "      <td>-5.380388</td>\n",
       "      <td>-3.658577</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.488512</td>\n",
       "      <td>-12.627724</td>\n",
       "      <td>-12.913944</td>\n",
       "      <td>-15.011854</td>\n",
       "      <td>-18.860261</td>\n",
       "      <td>-21.238805</td>\n",
       "      <td>-22.137217</td>\n",
       "      <td>-23.915206</td>\n",
       "      <td>-27.003360</td>\n",
       "      <td>-24.358719</td>\n",
       "      <td>-14.958878</td>\n",
       "      <td>-10.066057</td>\n",
       "      <td>-6.843982</td>\n",
       "      <td>-4.492913</td>\n",
       "      <td>-3.191575</td>\n",
       "      <td>-2.834656</td>\n",
       "      <td>-2.298204</td>\n",
       "      <td>-3.023312</td>\n",
       "      <td>-3.524936</td>\n",
       "      <td>-3.866469</td>\n",
       "      <td>-4.236668</td>\n",
       "      <td>-6.075979</td>\n",
       "      <td>-6.462602</td>\n",
       "      <td>-6.490086</td>\n",
       "      <td>-5.523988</td>\n",
       "      <td>-6.808219</td>\n",
       "      <td>-11.169137</td>\n",
       "      <td>-17.340306</td>\n",
       "      <td>-20.582039</td>\n",
       "      <td>-22.259705</td>\n",
       "      <td>-23.846770</td>\n",
       "      <td>-23.867451</td>\n",
       "      <td>-25.314444</td>\n",
       "      <td>-24.120343</td>\n",
       "      <td>-25.423557</td>\n",
       "      <td>-25.774556</td>\n",
       "      <td>-22.357973</td>\n",
       "      <td>-22.273973</td>\n",
       "      <td>-24.853915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.436894</td>\n",
       "      <td>-25.614001</td>\n",
       "      <td>-23.802954</td>\n",
       "      <td>-15.158523</td>\n",
       "      <td>-7.539637</td>\n",
       "      <td>-5.253020</td>\n",
       "      <td>-7.366501</td>\n",
       "      <td>-10.512463</td>\n",
       "      <td>-11.118834</td>\n",
       "      <td>-11.412631</td>\n",
       "      <td>-9.970023</td>\n",
       "      <td>-10.252454</td>\n",
       "      <td>-12.546367</td>\n",
       "      <td>-13.184998</td>\n",
       "      <td>-15.875084</td>\n",
       "      <td>-15.831312</td>\n",
       "      <td>-14.464615</td>\n",
       "      <td>-12.804901</td>\n",
       "      <td>-12.472990</td>\n",
       "      <td>-10.008247</td>\n",
       "      <td>-8.355015</td>\n",
       "      <td>-3.271981</td>\n",
       "      <td>0.738162</td>\n",
       "      <td>-0.352527</td>\n",
       "      <td>-4.148326</td>\n",
       "      <td>-1.231770</td>\n",
       "      <td>1.597498</td>\n",
       "      <td>1.129153</td>\n",
       "      <td>-2.638529</td>\n",
       "      <td>-4.126524</td>\n",
       "      <td>-6.357771</td>\n",
       "      <td>-10.682904</td>\n",
       "      <td>-18.283030</td>\n",
       "      <td>-18.860882</td>\n",
       "      <td>-19.660488</td>\n",
       "      <td>-19.750202</td>\n",
       "      <td>-12.065006</td>\n",
       "      <td>-10.242125</td>\n",
       "      <td>-10.448796</td>\n",
       "      <td>-9.667010</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.622553</td>\n",
       "      <td>-15.717974</td>\n",
       "      <td>-14.625128</td>\n",
       "      <td>-15.672617</td>\n",
       "      <td>-11.482865</td>\n",
       "      <td>-7.371888</td>\n",
       "      <td>-5.312112</td>\n",
       "      <td>-3.513985</td>\n",
       "      <td>-1.382509</td>\n",
       "      <td>-1.048110</td>\n",
       "      <td>-0.880102</td>\n",
       "      <td>-0.452932</td>\n",
       "      <td>-0.770737</td>\n",
       "      <td>-0.933147</td>\n",
       "      <td>-0.851610</td>\n",
       "      <td>-1.308815</td>\n",
       "      <td>-1.053886</td>\n",
       "      <td>-1.169214</td>\n",
       "      <td>-2.275628</td>\n",
       "      <td>-3.297978</td>\n",
       "      <td>-3.418816</td>\n",
       "      <td>-3.589221</td>\n",
       "      <td>-5.598546</td>\n",
       "      <td>-8.025823</td>\n",
       "      <td>-8.724397</td>\n",
       "      <td>-8.178847</td>\n",
       "      <td>-9.144625</td>\n",
       "      <td>-10.964461</td>\n",
       "      <td>-15.137102</td>\n",
       "      <td>-14.389808</td>\n",
       "      <td>-14.321583</td>\n",
       "      <td>-15.970696</td>\n",
       "      <td>-18.551996</td>\n",
       "      <td>-21.979510</td>\n",
       "      <td>-25.047777</td>\n",
       "      <td>-24.292181</td>\n",
       "      <td>-24.340515</td>\n",
       "      <td>-26.337542</td>\n",
       "      <td>-26.042201</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.857962</td>\n",
       "      <td>2.180288</td>\n",
       "      <td>-2.770249</td>\n",
       "      <td>-1.995826</td>\n",
       "      <td>-0.780680</td>\n",
       "      <td>-0.125302</td>\n",
       "      <td>-0.136835</td>\n",
       "      <td>-2.471162</td>\n",
       "      <td>-7.706022</td>\n",
       "      <td>-13.459490</td>\n",
       "      <td>-14.040008</td>\n",
       "      <td>-16.834766</td>\n",
       "      <td>-20.775208</td>\n",
       "      <td>-23.800922</td>\n",
       "      <td>-24.787725</td>\n",
       "      <td>-24.586521</td>\n",
       "      <td>-23.979071</td>\n",
       "      <td>-22.536275</td>\n",
       "      <td>-16.053445</td>\n",
       "      <td>-10.373548</td>\n",
       "      <td>-8.427776</td>\n",
       "      <td>-9.595952</td>\n",
       "      <td>-12.576156</td>\n",
       "      <td>-13.205725</td>\n",
       "      <td>-14.051876</td>\n",
       "      <td>-14.634588</td>\n",
       "      <td>-14.710397</td>\n",
       "      <td>-12.013880</td>\n",
       "      <td>-7.229247</td>\n",
       "      <td>-5.630402</td>\n",
       "      <td>-7.033965</td>\n",
       "      <td>-7.817953</td>\n",
       "      <td>-8.705202</td>\n",
       "      <td>-8.718037</td>\n",
       "      <td>-9.055076</td>\n",
       "      <td>-11.202615</td>\n",
       "      <td>-11.673589</td>\n",
       "      <td>-12.009576</td>\n",
       "      <td>-15.914419</td>\n",
       "      <td>-18.248776</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.552037</td>\n",
       "      <td>-6.634409</td>\n",
       "      <td>-6.136538</td>\n",
       "      <td>-6.048594</td>\n",
       "      <td>-4.214014</td>\n",
       "      <td>-3.243250</td>\n",
       "      <td>-5.907762</td>\n",
       "      <td>-9.141914</td>\n",
       "      <td>-10.232233</td>\n",
       "      <td>-8.783634</td>\n",
       "      <td>-5.757603</td>\n",
       "      <td>-4.473499</td>\n",
       "      <td>-3.499962</td>\n",
       "      <td>-4.337528</td>\n",
       "      <td>-4.677007</td>\n",
       "      <td>-5.521075</td>\n",
       "      <td>-3.069710</td>\n",
       "      <td>-4.638232</td>\n",
       "      <td>-5.834335</td>\n",
       "      <td>-4.799331</td>\n",
       "      <td>-5.610016</td>\n",
       "      <td>-7.142639</td>\n",
       "      <td>-7.649345</td>\n",
       "      <td>-10.227697</td>\n",
       "      <td>-12.666223</td>\n",
       "      <td>-19.119767</td>\n",
       "      <td>-21.233922</td>\n",
       "      <td>-21.995479</td>\n",
       "      <td>-23.698103</td>\n",
       "      <td>-27.778395</td>\n",
       "      <td>-27.038454</td>\n",
       "      <td>-26.411519</td>\n",
       "      <td>-25.299244</td>\n",
       "      <td>-25.261126</td>\n",
       "      <td>-24.063918</td>\n",
       "      <td>-24.168632</td>\n",
       "      <td>-23.207541</td>\n",
       "      <td>-23.683942</td>\n",
       "      <td>-23.100682</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.171939</td>\n",
       "      <td>6.345472</td>\n",
       "      <td>-14.378912</td>\n",
       "      <td>-15.434625</td>\n",
       "      <td>-13.171749</td>\n",
       "      <td>-12.466776</td>\n",
       "      <td>-9.944689</td>\n",
       "      <td>-6.855007</td>\n",
       "      <td>-5.904826</td>\n",
       "      <td>-4.828486</td>\n",
       "      <td>-5.179103</td>\n",
       "      <td>-4.763272</td>\n",
       "      <td>-4.625385</td>\n",
       "      <td>-5.232233</td>\n",
       "      <td>-6.035913</td>\n",
       "      <td>-5.835548</td>\n",
       "      <td>-5.503596</td>\n",
       "      <td>-3.380965</td>\n",
       "      <td>-3.071690</td>\n",
       "      <td>-1.521376</td>\n",
       "      <td>-2.162901</td>\n",
       "      <td>-4.140971</td>\n",
       "      <td>-5.555904</td>\n",
       "      <td>-6.060420</td>\n",
       "      <td>-4.722681</td>\n",
       "      <td>-4.290475</td>\n",
       "      <td>-3.439849</td>\n",
       "      <td>-1.189634</td>\n",
       "      <td>-1.050191</td>\n",
       "      <td>-2.886996</td>\n",
       "      <td>-6.491181</td>\n",
       "      <td>-11.630248</td>\n",
       "      <td>-14.716508</td>\n",
       "      <td>-15.363808</td>\n",
       "      <td>-17.000927</td>\n",
       "      <td>-17.584142</td>\n",
       "      <td>-17.160508</td>\n",
       "      <td>-18.008622</td>\n",
       "      <td>-20.726344</td>\n",
       "      <td>-10.230954</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.532414</td>\n",
       "      <td>-3.650546</td>\n",
       "      <td>-7.645953</td>\n",
       "      <td>-10.870672</td>\n",
       "      <td>-12.840617</td>\n",
       "      <td>-17.241195</td>\n",
       "      <td>-19.362465</td>\n",
       "      <td>-21.974507</td>\n",
       "      <td>-20.374063</td>\n",
       "      <td>-10.833699</td>\n",
       "      <td>-6.844537</td>\n",
       "      <td>-6.436191</td>\n",
       "      <td>-7.613826</td>\n",
       "      <td>-8.317657</td>\n",
       "      <td>-11.927867</td>\n",
       "      <td>-17.154351</td>\n",
       "      <td>-21.707840</td>\n",
       "      <td>-23.555225</td>\n",
       "      <td>-25.875313</td>\n",
       "      <td>-26.730253</td>\n",
       "      <td>-26.132212</td>\n",
       "      <td>-24.226497</td>\n",
       "      <td>-16.483340</td>\n",
       "      <td>-13.141508</td>\n",
       "      <td>-11.277110</td>\n",
       "      <td>-9.001057</td>\n",
       "      <td>-8.182750</td>\n",
       "      <td>-8.937614</td>\n",
       "      <td>-5.688620</td>\n",
       "      <td>-2.298828</td>\n",
       "      <td>-1.840615</td>\n",
       "      <td>-2.837490</td>\n",
       "      <td>-3.528641</td>\n",
       "      <td>-4.303278</td>\n",
       "      <td>-4.213942</td>\n",
       "      <td>-3.902625</td>\n",
       "      <td>-3.046322</td>\n",
       "      <td>-1.718037</td>\n",
       "      <td>0.842056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2  ...        214        215  label\n",
       "0 -14.260570  -9.794443  -7.310346  ...  -2.250857  -1.219765    0.0\n",
       "1 -23.247869 -21.882432 -22.464536  ... -22.273973 -24.853915    0.0\n",
       "3 -27.436894 -25.614001 -23.802954  ... -26.337542 -26.042201    0.0\n",
       "4   4.857962   2.180288  -2.770249  ... -23.683942 -23.100682    0.0\n",
       "5  11.171939   6.345472 -14.378912  ...  -1.718037   0.842056    0.0\n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df2.rename(columns={216: \"label\"})\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oD4D1Q1u8Bzq",
    "outputId": "befeaa26-abea-4bcb-b674-38569de695b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282, 216)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(new_df.drop('label',axis=1),\\\n",
    "                                                 new_df['label'],random_state=5)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "1uw0SWyi8FGE",
    "outputId": "b3103469-2e82-456e-f801-31a1d20f0ebf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    0.294326\n",
       "0.0    0.276596\n",
       "3.0    0.234043\n",
       "1.0    0.195035\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "bE9zoYQK8HT2",
    "outputId": "24a5315f-8dea-4f67-e839-24526b2f6fc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    0.308511\n",
       "0.0    0.276596\n",
       "2.0    0.265957\n",
       "1.0    0.148936\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZDZE1wo8Wn-"
   },
   "source": [
    "## randomforest classifier training accuracy-1.00 testing accuracy-0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "zKxw5GI48JRI",
    "outputId": "6dc246f8-08ea-4abb-adb2-72dc33bf7cf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159    1.0\n",
       "476    3.0\n",
       "141    1.0\n",
       "139    1.0\n",
       "432    3.0\n",
       "      ... \n",
       "86     0.0\n",
       "144    1.0\n",
       "257    2.0\n",
       "276    2.0\n",
       "452    3.0\n",
       "Name: label, Length: 282, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyBc9qoRIEjM"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "nROiUDJyIEtZ",
    "outputId": "f8e448b7-5ae2-4699-8c8a-8ec8a59feafa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "zvm9CTEbILl0",
    "outputId": "811c1e38-53e5-479a-e6f0-f41c42e69461"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159    1.0\n",
       "476    3.0\n",
       "141    1.0\n",
       "139    1.0\n",
       "432    3.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "8LZsBtA9IL0Z",
    "outputId": "e008d980-cc62-4e67-fc48-578ddc9a730d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 512)               111104    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 144,196\n",
      "Trainable params: 144,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Bulding the model\n",
    "model_ann = Sequential()\n",
    "model_ann.add(Dense(512,input_shape=(216,),activation='relu'))\n",
    "model_ann.add(Dense(64,activation='relu'))\n",
    "model_ann.add(Dense(4,activation='softmax'))\n",
    "model_ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOWpgfYzILxm"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_ann.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "id": "KrtPq3JDIg4Z",
    "outputId": "44124203-f109-43ae-cf8b-4944fd930742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 282 samples, validate on 94 samples\n",
      "Epoch 1/20\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 12.0526 - accuracy: 0.3475 - val_loss: 6.0486 - val_accuracy: 0.3404\n",
      "Epoch 2/20\n",
      "282/282 [==============================] - 0s 153us/step - loss: 3.8498 - accuracy: 0.3723 - val_loss: 3.1464 - val_accuracy: 0.3830\n",
      "Epoch 3/20\n",
      "282/282 [==============================] - 0s 146us/step - loss: 2.0332 - accuracy: 0.4787 - val_loss: 1.9883 - val_accuracy: 0.4468\n",
      "Epoch 4/20\n",
      "282/282 [==============================] - 0s 151us/step - loss: 1.4096 - accuracy: 0.5426 - val_loss: 1.7876 - val_accuracy: 0.4681\n",
      "Epoch 5/20\n",
      "282/282 [==============================] - 0s 149us/step - loss: 0.9455 - accuracy: 0.6277 - val_loss: 1.4552 - val_accuracy: 0.5319\n",
      "Epoch 6/20\n",
      "282/282 [==============================] - 0s 158us/step - loss: 0.7182 - accuracy: 0.7163 - val_loss: 1.5099 - val_accuracy: 0.5106\n",
      "Epoch 7/20\n",
      "282/282 [==============================] - 0s 156us/step - loss: 0.7019 - accuracy: 0.7128 - val_loss: 1.4991 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "282/282 [==============================] - 0s 156us/step - loss: 0.6642 - accuracy: 0.7340 - val_loss: 1.2560 - val_accuracy: 0.5851\n",
      "Epoch 9/20\n",
      "282/282 [==============================] - 0s 156us/step - loss: 0.4965 - accuracy: 0.7943 - val_loss: 1.2316 - val_accuracy: 0.5957\n",
      "Epoch 10/20\n",
      "282/282 [==============================] - 0s 150us/step - loss: 0.5249 - accuracy: 0.7766 - val_loss: 1.5384 - val_accuracy: 0.5532\n",
      "Epoch 11/20\n",
      "282/282 [==============================] - 0s 153us/step - loss: 0.5296 - accuracy: 0.8156 - val_loss: 1.1900 - val_accuracy: 0.5957\n",
      "Epoch 12/20\n",
      "282/282 [==============================] - 0s 148us/step - loss: 0.4510 - accuracy: 0.8156 - val_loss: 1.3840 - val_accuracy: 0.5745\n",
      "Epoch 13/20\n",
      "282/282 [==============================] - 0s 160us/step - loss: 0.4407 - accuracy: 0.8404 - val_loss: 1.2864 - val_accuracy: 0.5957\n",
      "Epoch 14/20\n",
      "282/282 [==============================] - 0s 167us/step - loss: 0.4004 - accuracy: 0.8688 - val_loss: 1.4420 - val_accuracy: 0.5851\n",
      "Epoch 15/20\n",
      "282/282 [==============================] - 0s 174us/step - loss: 0.3989 - accuracy: 0.8688 - val_loss: 1.2192 - val_accuracy: 0.5426\n",
      "Epoch 16/20\n",
      "282/282 [==============================] - 0s 152us/step - loss: 0.3887 - accuracy: 0.8475 - val_loss: 1.3817 - val_accuracy: 0.6170\n",
      "Epoch 17/20\n",
      "282/282 [==============================] - 0s 156us/step - loss: 0.3832 - accuracy: 0.8582 - val_loss: 1.2044 - val_accuracy: 0.5532\n",
      "Epoch 18/20\n",
      "282/282 [==============================] - 0s 148us/step - loss: 0.2784 - accuracy: 0.9078 - val_loss: 1.3169 - val_accuracy: 0.5638\n",
      "Epoch 19/20\n",
      "282/282 [==============================] - 0s 146us/step - loss: 0.2382 - accuracy: 0.9397 - val_loss: 1.2438 - val_accuracy: 0.5426\n",
      "Epoch 20/20\n",
      "282/282 [==============================] - 0s 152us/step - loss: 0.2044 - accuracy: 0.9574 - val_loss: 1.2575 - val_accuracy: 0.5745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6cd6fc1f28>"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the model\n",
    "model_ann.fit(X_train,y_train_cat,epochs=20,validation_data=(X_test,y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xLJEKPG38aP1",
    "outputId": "c29c6ff2-2832-48a5-979a-fd9c53ecd14b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 216)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUT9bkVV8mDE"
   },
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nBOnsSV68oFx",
    "outputId": "4ccb463d-9045-4efe-cf8e-fe9eb3ae0fe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 216, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lSaaxLfBEAEF",
    "outputId": "506d6c2a-d0c5-443f-950e-f4ac6c0afad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Number of training samples: 282\n",
      "[+] Number of testing samples: 94\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = load_data(test_size=0.25)\n",
    "\n",
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dT1jHnJDEQPP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train)\n",
    "y_train= np.asarray(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Oc0tG4eCEVXE",
    "outputId": "6b5a918c-fe91-4dd7-e226-4243db2dc51d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((282, 216), (282,), (94, 216), (94,))"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laZ5i_OTEd8x"
   },
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W1SgdHBtEh9n",
    "outputId": "add69df7-0968-45ab-e196-bcec1cce922f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((282, 216, 1), (94, 216, 1))"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape,x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jx_-UVXl8qIK"
   },
   "outputs": [],
   "source": [
    "## Bulid the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvgL08xRDZTS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "id": "NeWeAHKK8uiY",
    "outputId": "c07d196c-114d-471b-ebf7-0a7e7fa6348f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 13828     \n",
      "=================================================================\n",
      "Total params: 343,428\n",
      "Trainable params: 343,428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_3V7ZEr9DGB"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5I-xVV9wAhVH",
    "outputId": "35efcf7d-70da-40ff-c559-d9e71486c4b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 282 samples, validate on 94 samples\n",
      "Epoch 1/100\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 1.6810 - accuracy: 0.2943 - val_loss: 1.4228 - val_accuracy: 0.3085\n",
      "Epoch 2/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.3779 - accuracy: 0.3227 - val_loss: 1.3297 - val_accuracy: 0.3830\n",
      "Epoch 3/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.2953 - accuracy: 0.4255 - val_loss: 1.2956 - val_accuracy: 0.4149\n",
      "Epoch 4/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.2642 - accuracy: 0.4610 - val_loss: 1.2799 - val_accuracy: 0.4149\n",
      "Epoch 5/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.2384 - accuracy: 0.4610 - val_loss: 1.2604 - val_accuracy: 0.4468\n",
      "Epoch 6/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.2176 - accuracy: 0.4858 - val_loss: 1.2541 - val_accuracy: 0.4255\n",
      "Epoch 7/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.2001 - accuracy: 0.4894 - val_loss: 1.2443 - val_accuracy: 0.4362\n",
      "Epoch 8/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.1802 - accuracy: 0.5106 - val_loss: 1.2210 - val_accuracy: 0.4787\n",
      "Epoch 9/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.1602 - accuracy: 0.5319 - val_loss: 1.2174 - val_accuracy: 0.4468\n",
      "Epoch 10/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.1476 - accuracy: 0.5177 - val_loss: 1.2076 - val_accuracy: 0.4574\n",
      "Epoch 11/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.1309 - accuracy: 0.5284 - val_loss: 1.1827 - val_accuracy: 0.4894\n",
      "Epoch 12/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.1126 - accuracy: 0.5390 - val_loss: 1.1757 - val_accuracy: 0.4681\n",
      "Epoch 13/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.0963 - accuracy: 0.5461 - val_loss: 1.1738 - val_accuracy: 0.4787\n",
      "Epoch 14/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.0849 - accuracy: 0.5532 - val_loss: 1.1525 - val_accuracy: 0.5106\n",
      "Epoch 15/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.0687 - accuracy: 0.5603 - val_loss: 1.1360 - val_accuracy: 0.4894\n",
      "Epoch 16/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.0514 - accuracy: 0.5709 - val_loss: 1.1247 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.0341 - accuracy: 0.5851 - val_loss: 1.1210 - val_accuracy: 0.4787\n",
      "Epoch 18/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.0234 - accuracy: 0.5603 - val_loss: 1.1134 - val_accuracy: 0.4787\n",
      "Epoch 19/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 1.0086 - accuracy: 0.5745 - val_loss: 1.0994 - val_accuracy: 0.4894\n",
      "Epoch 20/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.9975 - accuracy: 0.5887 - val_loss: 1.0829 - val_accuracy: 0.5106\n",
      "Epoch 21/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.9821 - accuracy: 0.6028 - val_loss: 1.0773 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.9666 - accuracy: 0.5816 - val_loss: 1.0609 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.9540 - accuracy: 0.5957 - val_loss: 1.0575 - val_accuracy: 0.5106\n",
      "Epoch 24/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.9380 - accuracy: 0.6170 - val_loss: 1.0403 - val_accuracy: 0.5426\n",
      "Epoch 25/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.9286 - accuracy: 0.6206 - val_loss: 1.0362 - val_accuracy: 0.5106\n",
      "Epoch 26/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.9145 - accuracy: 0.6241 - val_loss: 1.0329 - val_accuracy: 0.5106\n",
      "Epoch 27/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.9014 - accuracy: 0.6206 - val_loss: 1.0108 - val_accuracy: 0.5851\n",
      "Epoch 28/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8956 - accuracy: 0.6383 - val_loss: 1.0076 - val_accuracy: 0.5638\n",
      "Epoch 29/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8819 - accuracy: 0.6383 - val_loss: 0.9953 - val_accuracy: 0.5426\n",
      "Epoch 30/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8726 - accuracy: 0.6596 - val_loss: 0.9907 - val_accuracy: 0.5319\n",
      "Epoch 31/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8591 - accuracy: 0.6667 - val_loss: 0.9825 - val_accuracy: 0.5319\n",
      "Epoch 32/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8493 - accuracy: 0.6489 - val_loss: 0.9732 - val_accuracy: 0.5319\n",
      "Epoch 33/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8379 - accuracy: 0.6667 - val_loss: 0.9587 - val_accuracy: 0.5851\n",
      "Epoch 34/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8320 - accuracy: 0.6773 - val_loss: 0.9578 - val_accuracy: 0.5851\n",
      "Epoch 35/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8237 - accuracy: 0.6560 - val_loss: 0.9488 - val_accuracy: 0.5638\n",
      "Epoch 36/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8100 - accuracy: 0.6667 - val_loss: 0.9374 - val_accuracy: 0.6170\n",
      "Epoch 37/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.8041 - accuracy: 0.6702 - val_loss: 0.9316 - val_accuracy: 0.6170\n",
      "Epoch 38/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7924 - accuracy: 0.6702 - val_loss: 0.9255 - val_accuracy: 0.6277\n",
      "Epoch 39/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7866 - accuracy: 0.6702 - val_loss: 0.9192 - val_accuracy: 0.6170\n",
      "Epoch 40/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7780 - accuracy: 0.6809 - val_loss: 0.9054 - val_accuracy: 0.6489\n",
      "Epoch 41/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7651 - accuracy: 0.7057 - val_loss: 0.9042 - val_accuracy: 0.6383\n",
      "Epoch 42/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7587 - accuracy: 0.6809 - val_loss: 0.8958 - val_accuracy: 0.6383\n",
      "Epoch 43/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7531 - accuracy: 0.6950 - val_loss: 0.8992 - val_accuracy: 0.6383\n",
      "Epoch 44/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7429 - accuracy: 0.6986 - val_loss: 0.8840 - val_accuracy: 0.6489\n",
      "Epoch 45/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7355 - accuracy: 0.7163 - val_loss: 0.8840 - val_accuracy: 0.6383\n",
      "Epoch 46/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7281 - accuracy: 0.7128 - val_loss: 0.8710 - val_accuracy: 0.6702\n",
      "Epoch 47/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7221 - accuracy: 0.7092 - val_loss: 0.8631 - val_accuracy: 0.6915\n",
      "Epoch 48/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7115 - accuracy: 0.7270 - val_loss: 0.8628 - val_accuracy: 0.6596\n",
      "Epoch 49/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.7050 - accuracy: 0.7199 - val_loss: 0.8569 - val_accuracy: 0.6702\n",
      "Epoch 50/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6948 - accuracy: 0.7057 - val_loss: 0.8454 - val_accuracy: 0.7021\n",
      "Epoch 51/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6905 - accuracy: 0.7482 - val_loss: 0.8452 - val_accuracy: 0.6915\n",
      "Epoch 52/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6850 - accuracy: 0.7376 - val_loss: 0.8378 - val_accuracy: 0.6809\n",
      "Epoch 53/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6724 - accuracy: 0.7411 - val_loss: 0.8376 - val_accuracy: 0.6915\n",
      "Epoch 54/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6700 - accuracy: 0.7447 - val_loss: 0.8251 - val_accuracy: 0.7128\n",
      "Epoch 55/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6652 - accuracy: 0.7270 - val_loss: 0.8257 - val_accuracy: 0.7021\n",
      "Epoch 56/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6602 - accuracy: 0.7270 - val_loss: 0.8313 - val_accuracy: 0.6915\n",
      "Epoch 57/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6539 - accuracy: 0.7376 - val_loss: 0.8171 - val_accuracy: 0.7234\n",
      "Epoch 58/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6502 - accuracy: 0.7589 - val_loss: 0.8144 - val_accuracy: 0.7021\n",
      "Epoch 59/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6402 - accuracy: 0.7482 - val_loss: 0.8055 - val_accuracy: 0.7128\n",
      "Epoch 60/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6387 - accuracy: 0.7660 - val_loss: 0.8053 - val_accuracy: 0.7128\n",
      "Epoch 61/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6285 - accuracy: 0.7553 - val_loss: 0.7947 - val_accuracy: 0.7234\n",
      "Epoch 62/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6260 - accuracy: 0.7695 - val_loss: 0.8046 - val_accuracy: 0.7021\n",
      "Epoch 63/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6196 - accuracy: 0.7447 - val_loss: 0.7945 - val_accuracy: 0.7128\n",
      "Epoch 64/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6191 - accuracy: 0.7589 - val_loss: 0.7854 - val_accuracy: 0.7234\n",
      "Epoch 65/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6133 - accuracy: 0.7872 - val_loss: 0.7845 - val_accuracy: 0.7234\n",
      "Epoch 66/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6055 - accuracy: 0.7553 - val_loss: 0.7816 - val_accuracy: 0.7128\n",
      "Epoch 67/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.6017 - accuracy: 0.7837 - val_loss: 0.7812 - val_accuracy: 0.7021\n",
      "Epoch 68/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5912 - accuracy: 0.7766 - val_loss: 0.7755 - val_accuracy: 0.7128\n",
      "Epoch 69/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5915 - accuracy: 0.7730 - val_loss: 0.7843 - val_accuracy: 0.7021\n",
      "Epoch 70/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5859 - accuracy: 0.7730 - val_loss: 0.7802 - val_accuracy: 0.7021\n",
      "Epoch 71/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5757 - accuracy: 0.7837 - val_loss: 0.7822 - val_accuracy: 0.7021\n",
      "Epoch 72/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5736 - accuracy: 0.7589 - val_loss: 0.7754 - val_accuracy: 0.7128\n",
      "Epoch 73/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5663 - accuracy: 0.7943 - val_loss: 0.7705 - val_accuracy: 0.7128\n",
      "Epoch 74/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5649 - accuracy: 0.7872 - val_loss: 0.7617 - val_accuracy: 0.7128\n",
      "Epoch 75/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5592 - accuracy: 0.7801 - val_loss: 0.7580 - val_accuracy: 0.7128\n",
      "Epoch 76/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5549 - accuracy: 0.7766 - val_loss: 0.7508 - val_accuracy: 0.7234\n",
      "Epoch 77/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5548 - accuracy: 0.7908 - val_loss: 0.7553 - val_accuracy: 0.7234\n",
      "Epoch 78/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5468 - accuracy: 0.7943 - val_loss: 0.7695 - val_accuracy: 0.7021\n",
      "Epoch 79/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5473 - accuracy: 0.7908 - val_loss: 0.7475 - val_accuracy: 0.7234\n",
      "Epoch 80/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5384 - accuracy: 0.7943 - val_loss: 0.7578 - val_accuracy: 0.6915\n",
      "Epoch 81/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5375 - accuracy: 0.7872 - val_loss: 0.7703 - val_accuracy: 0.7021\n",
      "Epoch 82/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5323 - accuracy: 0.7801 - val_loss: 0.7472 - val_accuracy: 0.7128\n",
      "Epoch 83/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5301 - accuracy: 0.7872 - val_loss: 0.7511 - val_accuracy: 0.7234\n",
      "Epoch 84/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5228 - accuracy: 0.7908 - val_loss: 0.7423 - val_accuracy: 0.7128\n",
      "Epoch 85/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5177 - accuracy: 0.7979 - val_loss: 0.7591 - val_accuracy: 0.7021\n",
      "Epoch 86/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5215 - accuracy: 0.8014 - val_loss: 0.7426 - val_accuracy: 0.7128\n",
      "Epoch 87/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5137 - accuracy: 0.8014 - val_loss: 0.7352 - val_accuracy: 0.7340\n",
      "Epoch 88/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5052 - accuracy: 0.8262 - val_loss: 0.7354 - val_accuracy: 0.7128\n",
      "Epoch 89/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.5017 - accuracy: 0.8298 - val_loss: 0.7380 - val_accuracy: 0.7340\n",
      "Epoch 90/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4981 - accuracy: 0.8085 - val_loss: 0.7314 - val_accuracy: 0.7234\n",
      "Epoch 91/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4976 - accuracy: 0.8227 - val_loss: 0.7411 - val_accuracy: 0.7128\n",
      "Epoch 92/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4924 - accuracy: 0.8298 - val_loss: 0.7279 - val_accuracy: 0.7128\n",
      "Epoch 93/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4870 - accuracy: 0.8298 - val_loss: 0.7354 - val_accuracy: 0.7128\n",
      "Epoch 94/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4827 - accuracy: 0.8121 - val_loss: 0.7274 - val_accuracy: 0.7234\n",
      "Epoch 95/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4846 - accuracy: 0.8227 - val_loss: 0.7382 - val_accuracy: 0.6915\n",
      "Epoch 96/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4801 - accuracy: 0.8333 - val_loss: 0.7320 - val_accuracy: 0.7128\n",
      "Epoch 97/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4781 - accuracy: 0.8404 - val_loss: 0.7180 - val_accuracy: 0.7234\n",
      "Epoch 98/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4716 - accuracy: 0.8262 - val_loss: 0.7343 - val_accuracy: 0.6915\n",
      "Epoch 99/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4651 - accuracy: 0.8617 - val_loss: 0.7478 - val_accuracy: 0.6915\n",
      "Epoch 100/100\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.4638 - accuracy: 0.8440 - val_loss: 0.7472 - val_accuracy: 0.6809\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train_cat, batch_size=16, epochs=100, validation_data=(x_testcnn, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J9UfeTKcE_L1",
    "outputId": "34284846-70db-4cd7-d489-c4a79c7d6ccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8439716\n"
     ]
    }
   ],
   "source": [
    "print(cnnhistory.history['accuracy'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "gHzfLJBKJ1s7",
    "outputId": "f855b18b-e7bf-4175-c5d9-7b9347d28743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 2ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n",
      "Train score: 0.747173973854552\n",
      "Train accuracy: 0.6808510422706604\n",
      "Test score: 0.747173973854552\n",
      "Test accuracy: 0.6808510422706604\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_traincnn, y_train_cat)\n",
    "score, acc = model.evaluate(x_testcnn, y_test_cat)\n",
    "print('Train score:', score)\n",
    "print('Train accuracy:', acc)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fg_jSKYeJ2At"
   },
   "outputs": [],
   "source": [
    "cnn_accuracy=0.765\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2ePZyAC9u0U"
   },
   "outputs": [],
   "source": [
    "#ml algorithms\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "kNvuEH0f95tD",
    "outputId": "9cd9a478-453d-4992-fd49-fd906d0fce2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5319148936170213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.46      0.48        26\n",
      "         1.0       1.00      0.93      0.96        14\n",
      "         2.0       0.42      0.52      0.46        25\n",
      "         3.0       0.46      0.41      0.44        29\n",
      "\n",
      "    accuracy                           0.53        94\n",
      "   macro avg       0.60      0.58      0.59        94\n",
      "weighted avg       0.54      0.53      0.53        94\n",
      "\n",
      "[[12  0  8  6]\n",
      " [ 0 13  0  1]\n",
      " [ 5  0 13  7]\n",
      " [ 7  0 10 12]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DECISION TREE \"\"\"\n",
    "\n",
    "dtree_model = DecisionTreeClassifier(max_depth = 6).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "\n",
    "print(accuracy_score(y_true=y_test,y_pred=dtree_predictions))\n",
    "dtAccuracy=accuracy_score(y_true=y_test,y_pred=dtree_predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test,dtree_predictions)) \n",
    "# creating a confusion matrix \n",
    "print(confusion_matrix(y_test, dtree_predictions) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "EhJII2Lv_Vdq",
    "outputId": "436165bb-1924-47cc-b9a6-491e67a8b572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        78\n",
      "         1.0       1.00      1.00      1.00        55\n",
      "         2.0       1.00      1.00      1.00        83\n",
      "         3.0       1.00      1.00      1.00        66\n",
      "\n",
      "    accuracy                           1.00       282\n",
      "   macro avg       1.00      1.00      1.00       282\n",
      "weighted avg       1.00      1.00      1.00       282\n",
      "\n",
      "[[78  0  0  0]\n",
      " [ 0 55  0  0]\n",
      " [ 0  0 83  0]\n",
      " [ 0  0  0 66]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SUPPORT VECTOR MACHINE\"\"\"\n",
    "\"\"\"train accuracy\"\"\"\n",
    "\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_train) \n",
    "\n",
    "\n",
    "print(accuracy_score(y_true=y_train,y_pred=svm_predictions))\n",
    "svmAccuracy=accuracy_score(y_true=y_train,y_pred=svm_predictions)\n",
    "print(classification_report(y_train,svm_predictions)) \n",
    "# creating a confusion matrix \n",
    "print(confusion_matrix(y_train, svm_predictions) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "rRrH81-N_ZIW",
    "outputId": "aa064f58-2786-4029-d91d-96cb68998208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48936170212765956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.42      0.34        26\n",
      "         1.0       1.00      1.00      1.00        14\n",
      "         2.0       0.48      0.48      0.48        25\n",
      "         3.0       0.53      0.31      0.39        29\n",
      "\n",
      "    accuracy                           0.49        94\n",
      "   macro avg       0.57      0.55      0.55        94\n",
      "weighted avg       0.52      0.49      0.49        94\n",
      "\n",
      "[[11  0  8  7]\n",
      " [ 0 14  0  0]\n",
      " [12  0 12  1]\n",
      " [15  0  5  9]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SUPPORT VECTOR MACHINE\"\"\"\n",
    "\"\"\"test accuracy\"\"\"\n",
    "\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "\n",
    "\n",
    "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
    "svmAccuracy=accuracy_score(y_true=y_test,y_pred=svm_predictions)\n",
    "print(classification_report(y_test,svm_predictions)) \n",
    "# creating a confusion matrix \n",
    "print(confusion_matrix(y_test, svm_predictions) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "W1rF721k_cAG",
    "outputId": "f421e9ce-5f24-4d2b-d54e-9a9011506213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        78\n",
      "         1.0       1.00      1.00      1.00        55\n",
      "         2.0       1.00      1.00      1.00        83\n",
      "         3.0       1.00      1.00      1.00        66\n",
      "\n",
      "    accuracy                           1.00       282\n",
      "   macro avg       1.00      1.00      1.00       282\n",
      "weighted avg       1.00      1.00      1.00       282\n",
      "\n",
      "[[78  0  0  0]\n",
      " [ 0 55  0  0]\n",
      " [ 0  0 83  0]\n",
      " [ 0  0  0 66]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest\"\"\"\n",
    " \n",
    " \n",
    "classifier = RandomForestClassifier(n_estimators = 50, random_state = 0) \n",
    "  \n",
    "# fit the regressor with x and y data \n",
    "classifier.fit(X_train, y_train)   \n",
    "\n",
    "c_p = classifier.predict(X_train) \n",
    "\n",
    "\n",
    "print(accuracy_score(y_true=y_train,y_pred=c_p))\n",
    "rfAccuracy=accuracy_score(y_true=y_train,y_pred=c_p)\n",
    "print(classification_report(y_train,c_p)) \n",
    "# creating a confusion matrix \n",
    "print(confusion_matrix(y_train,c_p) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "Px4G_ivG_eKv",
    "outputId": "2b969349-6ed9-43d9-e011-52e68422fd1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6702127659574468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.62      0.60        26\n",
      "         1.0       0.93      1.00      0.97        14\n",
      "         2.0       0.63      0.68      0.65        25\n",
      "         3.0       0.64      0.55      0.59        29\n",
      "\n",
      "    accuracy                           0.67        94\n",
      "   macro avg       0.70      0.71      0.70        94\n",
      "weighted avg       0.67      0.67      0.67        94\n",
      "\n",
      "[[16  0  5  5]\n",
      " [ 0 14  0  0]\n",
      " [ 3  1 17  4]\n",
      " [ 8  0  5 16]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest\"\"\"\n",
    " \n",
    " \n",
    "classifier = RandomForestClassifier(n_estimators = 50, random_state = 0) \n",
    "  \n",
    "# fit the regressor with x and y data \n",
    "classifier.fit(X_train, y_train)   \n",
    "\n",
    "c_p = classifier.predict(X_test) \n",
    "\n",
    "\n",
    "print(accuracy_score(y_true=y_test,y_pred=c_p))\n",
    "rfAccuracy=accuracy_score(y_true=y_test,y_pred=c_p)\n",
    "print(classification_report(y_test,c_p)) \n",
    "# creating a confusion matrix \n",
    "print(confusion_matrix(y_test,c_p) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IQfpB3B_l4w"
   },
   "source": [
    "mlp classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMh1M2uI_gUC"
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'alpha': 0.01,\n",
    "    'batch_size': 256,\n",
    "    'epsilon': 1e-08, \n",
    "    'hidden_layer_sizes': (300,), \n",
    "    'learning_rate': 'adaptive', \n",
    "    'max_iter': 500, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZuaAa1dT_kro"
   },
   "outputs": [],
   "source": [
    "# initialize Multi Layer Perceptron classifier\n",
    "# with best parameters ( so far )\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "modelmlp = MLPClassifier(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EvmXu5rq_pxD",
    "outputId": "d363d539-3c79-460e-b2c6-dc248c0e71fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training the model...\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[*] Training the model...\")\n",
    "modelmlp.fit(X_train, y_train)\n",
    "\n",
    "# predict 75% of data to measure how good we are\n",
    "y_pred = modelmlp.predict(X_train)\n",
    "\n",
    "# calculate the accuracy\n",
    "mlpAccuracy = accuracy_score(y_true=y_train, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(mlpAccuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "ULB1r4IT_r25",
    "outputId": "15a42a6f-6997-40e7-adc5-163db0babc81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        78\n",
      "         1.0       1.00      1.00      1.00        55\n",
      "         2.0       1.00      1.00      1.00        83\n",
      "         3.0       1.00      1.00      1.00        66\n",
      "\n",
      "    accuracy                           1.00       282\n",
      "   macro avg       1.00      1.00      1.00       282\n",
      "weighted avg       1.00      1.00      1.00       282\n",
      "\n",
      "[[78  0  0  0]\n",
      " [ 0 55  0  0]\n",
      " [ 0  0 83  0]\n",
      " [ 0  0  0 66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix \n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "fZCZ9Qih_vOW",
    "outputId": "80666b2b-b219-42c9-c400-61c6cecc7ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training the model...\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[*] Training the model...\")\n",
    "modelmlp.fit(X_train, y_train)\n",
    "\n",
    "# predict 25% of data to measure how good we are\n",
    "y_pred = modelmlp.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "mlpAccuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(mlpAccuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "jedRWKok_yEJ",
    "outputId": "509250c8-25df-4702-f6fc-79ed22124cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      0.46      0.37        26\n",
      "         1.0       0.78      1.00      0.88        14\n",
      "         2.0       0.59      0.52      0.55        25\n",
      "         3.0       0.50      0.28      0.36        29\n",
      "\n",
      "    accuracy                           0.50        94\n",
      "   macro avg       0.55      0.56      0.54        94\n",
      "weighted avg       0.51      0.50      0.49        94\n",
      "\n",
      "[[12  0  7  7]\n",
      " [ 0 14  0  0]\n",
      " [11  0 13  1]\n",
      " [15  4  2  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix \n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eiEIL4L_0RK"
   },
   "outputs": [],
   "source": [
    "accuracy=[dtAccuracy*100,cnn_accuracy*100,mlpAccuracy*100,rfAccuracy*100,svmAccuracy*100]\n",
    "algos=[\"DecisionTree\",\"CNN\",\"MLP\",\"RandomForest\",\"SVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwyBAdJg_2RG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "uJbIwkBr_9s6",
    "outputId": "3814d6f2-3711-44b6-df7a-e3589b186a98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel(\"accuracy\")\n",
    "plt.bar(algos,accuracy,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6Al_OnC__1W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Speech emotion recognition[unknown dataset]",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
